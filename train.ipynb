{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Dependencies & Set Up\n",
    "In this step, we import the necessary libraries and set a fixed random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the Dataset\n",
    "We load the Heart Failure Prediction dataset from a CSV file and display the first few rows to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Add a Hypothetical Categorical Feature\n",
    "Most features in this dataset are numerical. If no categorical features exist, we add a hypothetical \"Smoking_Status\" feature to demonstrate one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Separate Features and Labels\n",
    "We split the dataset into:\n",
    "- `X`: The feature matrix (excluding the target variable)\n",
    "- `y`: The target variable (`DEATH_EVENT`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"HeartDisease\"])  # Features\n",
    "y = df[\"HeartDisease\"]  # Binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Identify Numerical & Categorical Features\n",
    "Here, we classify features into numerical and categorical types for appropriate preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
      "Categorical Features: ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical features\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_features = [\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\"]\n",
    "\n",
    "# Display feature types\n",
    "print(\"Numerical Features:\", num_features.tolist())\n",
    "print(\"Categorical Features:\", cat_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: One-Hot Encode Categorical Features\n",
    "Most machine learning models require numerical inputs. We use **One-Hot Encoding** to convert categorical features into numerical format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ExerciseAngina_Y</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  Sex_M  \\\n",
       "0   40        140          289          0    172      0.0    1.0   \n",
       "1   49        160          180          0    156      1.0    0.0   \n",
       "2   37        130          283          0     98      0.0    1.0   \n",
       "3   48        138          214          0    108      1.5    0.0   \n",
       "4   54        150          195          0    122      0.0    1.0   \n",
       "\n",
       "   ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  RestingECG_Normal  \\\n",
       "0                1.0                0.0               0.0                1.0   \n",
       "1                0.0                1.0               0.0                1.0   \n",
       "2                1.0                0.0               0.0                0.0   \n",
       "3                0.0                0.0               0.0                1.0   \n",
       "4                0.0                1.0               0.0                1.0   \n",
       "\n",
       "   RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  ST_Slope_Up  \n",
       "0            0.0               0.0            0.0          1.0  \n",
       "1            0.0               0.0            1.0          0.0  \n",
       "2            1.0               0.0            0.0          1.0  \n",
       "3            0.0               1.0            1.0          0.0  \n",
       "4            0.0               0.0            0.0          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[cat_features])\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_encoded = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(cat_features))\n",
    "\n",
    "# Drop original categorical features and merge with encoded ones\n",
    "X = X.drop(columns=cat_features).reset_index(drop=True)\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "\n",
    "# Display updated dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Stratified Train/Validation/Test Split\n",
    "We split the dataset into:\n",
    "- **70% Training Set**: Used for model training\n",
    "- **10% Validation Set**: Used for hyperparameter tuning\n",
    "- **20% Test Set**: Used only for final model evaluation\n",
    "\n",
    "We use **stratification** to maintain the original class distribution in all subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (642, 15), Validation set: (92, 15), Test set: (184, 15)\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified splitting (70% train, 10% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=RANDOM_SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, stratify=y_temp, random_state=RANDOM_SEED)\n",
    "\n",
    "# Display dataset sizes\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Standardize Numerical Features\n",
    "Standardization ensures all numerical features have the same scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize only numerical features\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "# Display standardized data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Train a Decision Tree Model\n",
    "We train a Decision Tree Classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DecisionTree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Make Predictions\n",
    "We use the trained Decision Tree model to predict the class labels on:\n",
    "- **Training Data** (to check for overfitting)\n",
    "- **Validation Data** (for hyperparameter tuning)\n",
    "- **Test Data** (for final evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Evaluate Model Performance\n",
    "We compute key classification metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision & Recall**: Measures balance between false positives and false negatives\n",
    "- **F1 Score**: Harmonic mean of precision & recall\n",
    "- **Confusion Matrix**: Breakdown of predictions per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Training Set:\n",
      "Accuracy: 0.9860\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       287\n",
      "           1       0.98      0.99      0.99       355\n",
      "\n",
      "    accuracy                           0.99       642\n",
      "   macro avg       0.99      0.99      0.99       642\n",
      "weighted avg       0.99      0.99      0.99       642\n",
      "\n",
      "Confusion Matrix:\n",
      "[[281   6]\n",
      " [  3 352]]\n",
      "\n",
      "Evaluation on Validation Set:\n",
      "Accuracy: 0.8478\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82        41\n",
      "           1       0.84      0.90      0.87        51\n",
      "\n",
      "    accuracy                           0.85        92\n",
      "   macro avg       0.85      0.84      0.84        92\n",
      "weighted avg       0.85      0.85      0.85        92\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32  9]\n",
      " [ 5 46]]\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Accuracy: 0.8370\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        82\n",
      "           1       0.87      0.83      0.85       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.83      0.84      0.84       184\n",
      "weighted avg       0.84      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69 13]\n",
      " [17 85]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\nEvaluation on {dataset_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Evaluate on all sets\n",
    "evaluate_model(y_train, y_train_pred, \"Training Set\")\n",
    "evaluate_model(y_val, y_val_pred, \"Validation Set\")\n",
    "evaluate_model(y_test, y_test_pred, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
